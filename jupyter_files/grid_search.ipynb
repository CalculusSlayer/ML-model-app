{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b669b995",
   "metadata": {},
   "source": [
    "This is our grid search document! Note that there are some keyboard interrupts in our output, because we ran everything again just to make sure it works prior to our final submission! Because the full search takes a long time, we interrupted the kernel. The code works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc6a5a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.framework.errors_impl import InvalidArgumentError\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc05c819",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train - [[0.53912913 0.69460631 0.5541304  1.        ]\n",
      " [0.69474787 0.72926939 0.71293327 0.06651257]\n",
      " [0.72108335 0.72747647 0.6717056  0.09779414]\n",
      " ...\n",
      " [0.40011971 0.40475123 0.4025042  0.02255257]\n",
      " [0.40026934 0.39489018 0.38616583 0.04220904]\n",
      " [0.36465659 0.36261766 0.36784242 0.02943177]]\n",
      "**************************************************\n",
      "X_test - [[0.36555439 0.37950097 0.37196519 0.01550283]\n",
      " [0.37827323 0.38936202 0.38097419 0.01553931]\n",
      " [0.37572946 0.37546691 0.37883646 0.00991563]\n",
      " ...\n",
      " [0.05132426 0.05079934 0.05481753 0.01289286]\n",
      " [0.05656142 0.05259226 0.05527561 0.01735301]\n",
      " [0.04952865 0.06618856 0.05329058 0.0570686 ]]\n",
      "**************************************************\n",
      "Y_train - [[0.69701067]\n",
      " [0.71894247]\n",
      " [0.66155926]\n",
      " ...\n",
      " [0.39762656]\n",
      " [0.37990086]\n",
      " [0.36472886]]\n",
      "**************************************************\n",
      "Y_test - [[3.80501728e-01]\n",
      " [3.78248460e-01]\n",
      " [3.72239748e-01]\n",
      " [3.77196936e-01]\n",
      " [3.80501728e-01]\n",
      " [3.78098242e-01]\n",
      " [3.78098242e-01]\n",
      " [3.71188223e-01]\n",
      " [3.73291272e-01]\n",
      " [3.72990837e-01]\n",
      " [3.67733213e-01]\n",
      " [3.84106955e-01]\n",
      " [3.89064143e-01]\n",
      " [3.91768064e-01]\n",
      " [3.91317410e-01]\n",
      " [4.18957488e-01]\n",
      " [4.23764458e-01]\n",
      " [4.23313805e-01]\n",
      " [4.25116419e-01]\n",
      " [4.35481448e-01]\n",
      " [4.30974914e-01]\n",
      " [4.23914676e-01]\n",
      " [4.20459667e-01]\n",
      " [4.25416854e-01]\n",
      " [4.26017726e-01]\n",
      " [4.25266637e-01]\n",
      " [4.23013369e-01]\n",
      " [4.15352261e-01]\n",
      " [4.16253568e-01]\n",
      " [3.95823945e-01]\n",
      " [3.92669371e-01]\n",
      " [3.95223073e-01]\n",
      " [3.94321767e-01]\n",
      " [3.74192579e-01]\n",
      " [3.65329728e-01]\n",
      " [3.77347153e-01]\n",
      " [3.82003906e-01]\n",
      " [3.80501728e-01]\n",
      " [3.92669371e-01]\n",
      " [4.01382004e-01]\n",
      " [4.03635271e-01]\n",
      " [4.01231786e-01]\n",
      " [4.21060538e-01]\n",
      " [4.21060538e-01]\n",
      " [4.27820339e-01]\n",
      " [4.29472735e-01]\n",
      " [4.51704972e-01]\n",
      " [4.59215863e-01]\n",
      " [4.76490912e-01]\n",
      " [4.65675229e-01]\n",
      " [4.46898002e-01]\n",
      " [4.45245606e-01]\n",
      " [4.39987983e-01]\n",
      " [4.35781884e-01]\n",
      " [4.34429923e-01]\n",
      " [4.34880577e-01]\n",
      " [4.50052576e-01]\n",
      " [4.40138200e-01]\n",
      " [4.50052576e-01]\n",
      " [4.31726003e-01]\n",
      " [4.39236893e-01]\n",
      " [4.44043864e-01]\n",
      " [4.49902358e-01]\n",
      " [4.47198438e-01]\n",
      " [4.30374042e-01]\n",
      " [4.16704221e-01]\n",
      " [4.27069250e-01]\n",
      " [4.21811627e-01]\n",
      " [4.22262280e-01]\n",
      " [3.94622202e-01]\n",
      " [3.66080817e-01]\n",
      " [3.57668619e-01]\n",
      " [3.68934956e-01]\n",
      " [3.73591708e-01]\n",
      " [3.62625807e-01]\n",
      " [3.60072105e-01]\n",
      " [3.67282560e-01]\n",
      " [3.58870362e-01]\n",
      " [3.29728106e-01]\n",
      " [3.34535076e-01]\n",
      " [3.33032898e-01]\n",
      " [3.22968304e-01]\n",
      " [3.19363076e-01]\n",
      " [2.95929097e-01]\n",
      " [3.00736067e-01]\n",
      " [2.84963197e-01]\n",
      " [2.67387712e-01]\n",
      " [2.82109058e-01]\n",
      " [2.76100346e-01]\n",
      " [2.60327475e-01]\n",
      " [2.70542286e-01]\n",
      " [2.84061890e-01]\n",
      " [2.87066246e-01]\n",
      " [3.04341295e-01]\n",
      " [2.91572781e-01]\n",
      " [2.80006009e-01]\n",
      " [2.70241851e-01]\n",
      " [2.74598167e-01]\n",
      " [2.65585098e-01]\n",
      " [2.54619198e-01]\n",
      " [2.35090882e-01]\n",
      " [2.11206249e-01]\n",
      " [2.32687397e-01]\n",
      " [2.34940664e-01]\n",
      " [2.44254169e-01]\n",
      " [2.23824546e-01]\n",
      " [2.35691753e-01]\n",
      " [2.22923239e-01]\n",
      " [2.11807120e-01]\n",
      " [2.15111912e-01]\n",
      " [2.53267237e-01]\n",
      " [2.64533574e-01]\n",
      " [2.66786841e-01]\n",
      " [2.58825297e-01]\n",
      " [2.61829653e-01]\n",
      " [2.63331831e-01]\n",
      " [2.70392068e-01]\n",
      " [2.61529217e-01]\n",
      " [2.45756347e-01]\n",
      " [2.49061139e-01]\n",
      " [2.68889890e-01]\n",
      " [2.76851435e-01]\n",
      " [2.63181613e-01]\n",
      " [2.46507436e-01]\n",
      " [2.78654048e-01]\n",
      " [2.66786841e-01]\n",
      " [2.68289019e-01]\n",
      " [2.51013970e-01]\n",
      " [2.28931951e-01]\n",
      " [2.26077813e-01]\n",
      " [2.21871714e-01]\n",
      " [2.24725852e-01]\n",
      " [2.22322367e-01]\n",
      " [2.35841971e-01]\n",
      " [2.38996545e-01]\n",
      " [2.42151119e-01]\n",
      " [2.52365931e-01]\n",
      " [2.66937059e-01]\n",
      " [2.86615593e-01]\n",
      " [2.95178008e-01]\n",
      " [2.95178008e-01]\n",
      " [2.84362325e-01]\n",
      " [2.86315157e-01]\n",
      " [2.77302088e-01]\n",
      " [2.98032147e-01]\n",
      " [2.87516900e-01]\n",
      " [2.91422563e-01]\n",
      " [2.90070602e-01]\n",
      " [3.13805017e-01]\n",
      " [3.02238245e-01]\n",
      " [3.05993691e-01]\n",
      " [3.06294126e-01]\n",
      " [2.96529968e-01]\n",
      " [2.98332582e-01]\n",
      " [2.90521256e-01]\n",
      " [2.75799910e-01]\n",
      " [2.72194682e-01]\n",
      " [2.69640979e-01]\n",
      " [2.67537930e-01]\n",
      " [2.77902959e-01]\n",
      " [2.58524861e-01]\n",
      " [2.65735316e-01]\n",
      " [2.70842722e-01]\n",
      " [2.61979871e-01]\n",
      " [2.71744029e-01]\n",
      " [2.86315157e-01]\n",
      " [2.84512543e-01]\n",
      " [2.86315157e-01]\n",
      " [2.85564068e-01]\n",
      " [2.77001652e-01]\n",
      " [2.57923990e-01]\n",
      " [2.44704822e-01]\n",
      " [2.43653297e-01]\n",
      " [2.30283912e-01]\n",
      " [2.30133694e-01]\n",
      " [2.39146763e-01]\n",
      " [2.57473336e-01]\n",
      " [2.46507436e-01]\n",
      " [2.57323119e-01]\n",
      " [2.61979871e-01]\n",
      " [2.59426168e-01]\n",
      " [2.71143158e-01]\n",
      " [2.60477693e-01]\n",
      " [2.65585098e-01]\n",
      " [2.60627910e-01]\n",
      " [2.79254920e-01]\n",
      " [2.86164939e-01]\n",
      " [3.02839117e-01]\n",
      " [3.04641731e-01]\n",
      " [3.02088028e-01]\n",
      " [3.04341295e-01]\n",
      " [2.85864504e-01]\n",
      " [2.85864504e-01]\n",
      " [2.69340544e-01]\n",
      " [2.62730960e-01]\n",
      " [2.84662761e-01]\n",
      " [3.03439988e-01]\n",
      " [3.07646087e-01]\n",
      " [3.06143909e-01]\n",
      " [2.99534325e-01]\n",
      " [2.92474087e-01]\n",
      " [2.72194682e-01]\n",
      " [2.75199039e-01]\n",
      " [2.44404386e-01]\n",
      " [2.40949377e-01]\n",
      " [2.50563317e-01]\n",
      " [2.48760703e-01]\n",
      " [2.36142406e-01]\n",
      " [2.41850683e-01]\n",
      " [2.32537179e-01]\n",
      " [2.13759952e-01]\n",
      " [1.89124230e-01]\n",
      " [2.04596665e-01]\n",
      " [2.16163437e-01]\n",
      " [2.06399279e-01]\n",
      " [2.08502328e-01]\n",
      " [2.23824546e-01]\n",
      " [2.05197536e-01]\n",
      " [2.06699715e-01]\n",
      " [2.09553853e-01]\n",
      " [2.02042962e-01]\n",
      " [1.92879676e-01]\n",
      " [1.72149617e-01]\n",
      " [1.84167042e-01]\n",
      " [2.01892744e-01]\n",
      " [2.06699715e-01]\n",
      " [1.93180111e-01]\n",
      " [1.93931200e-01]\n",
      " [1.90025537e-01]\n",
      " [1.90926844e-01]\n",
      " [1.73802013e-01]\n",
      " [1.76656151e-01]\n",
      " [2.03244705e-01]\n",
      " [2.02944269e-01]\n",
      " [2.00090131e-01]\n",
      " [1.74853538e-01]\n",
      " [1.42406489e-01]\n",
      " [1.72600270e-01]\n",
      " [1.32191678e-01]\n",
      " [1.30839718e-01]\n",
      " [1.00195283e-01]\n",
      " [1.06203996e-01]\n",
      " [1.03650293e-01]\n",
      " [3.90566321e-02]\n",
      " [6.68469280e-02]\n",
      " [5.19753643e-02]\n",
      " [5.19753643e-02]\n",
      " [4.19107706e-02]\n",
      " [3.81553252e-02]\n",
      " [6.35421361e-02]\n",
      " [6.78984528e-02]\n",
      " [8.86285113e-02]\n",
      " [8.68258976e-02]\n",
      " [8.17184918e-02]\n",
      " [8.89289470e-02]\n",
      " [8.05167493e-02]\n",
      " [9.08817786e-02]\n",
      " [1.06203996e-01]\n",
      " [1.09058134e-01]\n",
      " [1.10710530e-01]\n",
      " [1.14766411e-01]\n",
      " [1.01096590e-01]\n",
      " [8.54739372e-02]\n",
      " [9.05813429e-02]\n",
      " [9.11822142e-02]\n",
      " [7.94652246e-02]\n",
      " [8.27700165e-02]\n",
      " [7.46582545e-02]\n",
      " [8.80276401e-02]\n",
      " [1.14015322e-01]\n",
      " [9.53883131e-02]\n",
      " [8.24695809e-02]\n",
      " [6.97010665e-02]\n",
      " [6.08382154e-02]\n",
      " [5.54303740e-02]\n",
      " [5.37779781e-02]\n",
      " [4.89710080e-02]\n",
      " [6.02373441e-02]\n",
      " [5.43788493e-02]\n",
      " [5.72329878e-02]\n",
      " [3.34985729e-02]\n",
      " [3.92068499e-02]\n",
      " [3.81553252e-02]\n",
      " [4.19107706e-02]\n",
      " [4.40138200e-02]\n",
      " [5.01727505e-02]\n",
      " [6.08382154e-02]\n",
      " [7.01517200e-02]\n",
      " [9.23839567e-02]\n",
      " [1.14165540e-01]\n",
      " [9.86931050e-02]\n",
      " [9.35856993e-02]\n",
      " [8.92293826e-02]\n",
      " [1.03049422e-01]\n",
      " [1.08607481e-01]\n",
      " [1.01397026e-01]\n",
      " [9.05813429e-02]\n",
      " [8.15682740e-02]\n",
      " [7.24049872e-02]\n",
      " [6.47438786e-02]\n",
      " [6.18897401e-02]\n",
      " [5.67823344e-02]\n",
      " [8.12678384e-02]\n",
      " [8.02163137e-02]\n",
      " [9.94441941e-02]\n",
      " [1.00045065e-01]\n",
      " [9.31350458e-02]\n",
      " [8.96800361e-02]\n",
      " [9.47874418e-02]\n",
      " [7.30058585e-02]\n",
      " [6.69971459e-02]\n",
      " [7.00015022e-02]\n",
      " [6.92504131e-02]\n",
      " [7.42076010e-02]\n",
      " [7.60102148e-02]\n",
      " [6.69971459e-02]\n",
      " [6.69971459e-02]\n",
      " [5.96364729e-02]\n",
      " [6.20399579e-02]\n",
      " [5.99369085e-02]\n",
      " [5.31771068e-02]\n",
      " [5.24260177e-02]\n",
      " [4.68679585e-02]\n",
      " [6.02373441e-02]\n",
      " [6.74477993e-02]\n",
      " [6.77482349e-02]\n",
      " [7.07525913e-02]\n",
      " [6.87997597e-02]\n",
      " [6.32417005e-02]\n",
      " [5.82845125e-02]\n",
      " [5.97866907e-02]\n",
      " [6.20399579e-02]\n",
      " [5.42286315e-02]\n",
      " [5.61814631e-02]\n",
      " [5.36277603e-02]\n",
      " [5.46792850e-02]\n",
      " [5.37779781e-02]\n",
      " [5.49797206e-02]\n",
      " [5.76836413e-02]\n",
      " [5.61814631e-02]\n",
      " [5.87351660e-02]\n",
      " [5.45290671e-02]\n",
      " [5.52801562e-02]\n",
      " [6.39927895e-02]\n",
      " [7.64608683e-02]\n",
      " [7.84136999e-02]\n",
      " [7.37569476e-02]\n",
      " [8.39717591e-02]\n",
      " [8.69761154e-02]\n",
      " [8.78774223e-02]\n",
      " [8.98302539e-02]\n",
      " [9.43367883e-02]\n",
      " [9.01306895e-02]\n",
      " [8.56241550e-02]\n",
      " [7.15036803e-02]\n",
      " [6.87997597e-02]\n",
      " [7.73621752e-02]\n",
      " [7.55595614e-02]\n",
      " [6.57954033e-02]\n",
      " [6.42932252e-02]\n",
      " [5.82845125e-02]\n",
      " [4.92714436e-02]\n",
      " [4.83701367e-02]\n",
      " [4.37133844e-02]\n",
      " [4.32627310e-02]\n",
      " [4.07090281e-02]\n",
      " [3.99579390e-02]\n",
      " [4.13098994e-02]\n",
      " [3.93570677e-02]\n",
      " [3.33483551e-02]\n",
      " [2.70392068e-02]\n",
      " [3.15457413e-02]\n",
      " [1.54724350e-02]\n",
      " [1.96785339e-02]\n",
      " [2.83911672e-02]\n",
      " [2.13309298e-02]\n",
      " [1.63737419e-02]\n",
      " [2.01291873e-02]\n",
      " [2.35841971e-02]\n",
      " [1.87772270e-02]\n",
      " [1.17169896e-02]\n",
      " [8.26197987e-03]\n",
      " [1.30689500e-02]\n",
      " [7.96154424e-03]\n",
      " [9.91437584e-03]\n",
      " [0.00000000e+00]\n",
      " [1.50217816e-04]\n",
      " [2.40348505e-03]\n",
      " [1.24680787e-02]\n",
      " [9.31350458e-03]\n",
      " [1.36698212e-02]\n",
      " [1.57728707e-02]\n",
      " [2.14811477e-02]\n",
      " [1.20174253e-02]\n",
      " [1.02148115e-02]\n",
      " [6.45936608e-03]\n",
      " [9.01306895e-04]\n",
      " [1.09659006e-02]\n",
      " [1.54724350e-02]\n",
      " [1.78759201e-02]\n",
      " [1.27685143e-02]\n",
      " [2.79405137e-02]\n",
      " [3.37990086e-02]\n",
      " [3.36487907e-02]\n",
      " [4.28120775e-02]\n",
      " [4.59666516e-02]\n",
      " [3.47003155e-02]\n",
      " [4.61168695e-02]\n",
      " [4.97220970e-02]\n",
      " [5.45290671e-02]\n",
      " [5.31771068e-02]\n",
      " [3.45500976e-02]\n",
      " [3.27474839e-02]\n",
      " [3.66531471e-02]\n",
      " [3.81553252e-02]\n",
      " [4.02583746e-02]\n",
      " [4.35631666e-02]\n",
      " [4.50653447e-02]\n",
      " [4.76190476e-02]\n",
      " [5.76836413e-02]\n",
      " [6.87997597e-02]\n",
      " [6.83491062e-02]\n",
      " [7.88643533e-02]\n",
      " [7.12032447e-02]\n",
      " [7.25552050e-02]\n",
      " [7.30058585e-02]\n",
      " [8.32206700e-02]\n",
      " [9.85428872e-02]\n",
      " [9.77917981e-02]\n",
      " [1.05002253e-01]\n",
      " [9.88433228e-02]\n",
      " [9.35856993e-02]\n",
      " [6.72975815e-02]\n",
      " [7.49586901e-02]\n",
      " [7.36067298e-02]\n",
      " [7.72119573e-02]\n",
      " [8.14180562e-02]\n",
      " [7.37569476e-02]\n",
      " [7.52591257e-02]\n",
      " [7.48084723e-02]\n",
      " [7.45080367e-02]\n",
      " [8.02163137e-02]\n",
      " [7.39071654e-02]\n",
      " [7.37569476e-02]\n",
      " [7.79630464e-02]\n",
      " [8.75769866e-02]\n",
      " [9.35856993e-02]\n",
      " [1.08457263e-01]\n",
      " [1.05903560e-01]\n",
      " [1.08457263e-01]\n",
      " [9.82424516e-02]\n",
      " [8.45726303e-02]\n",
      " [8.87787292e-02]\n",
      " [9.29848280e-02]\n",
      " [8.05167493e-02]\n",
      " [6.80486706e-02]\n",
      " [6.39927895e-02]\n",
      " [5.58810275e-02]\n",
      " [5.30268890e-02]\n",
      " [4.61168695e-02]\n",
      " [5.54303740e-02]\n",
      " [6.21901758e-02]\n",
      " [8.02163137e-02]\n",
      " [9.92939763e-02]\n",
      " [9.10319964e-02]\n",
      " [9.31350458e-02]\n",
      " [8.62250263e-02]\n",
      " [8.33708878e-02]\n",
      " [7.99158780e-02]\n",
      " [7.00015022e-02]\n",
      " [6.51945321e-02]\n",
      " [6.97010665e-02]\n",
      " [7.40573832e-02]\n",
      " [8.83280757e-02]\n",
      " [8.62250263e-02]\n",
      " [7.72119573e-02]\n",
      " [7.91647889e-02]\n",
      " [1.01697461e-01]\n",
      " [1.36848430e-01]\n",
      " [1.25131441e-01]\n",
      " [1.31590807e-01]\n",
      " [1.28736668e-01]\n",
      " [1.33243203e-01]\n",
      " [1.24680787e-01]\n",
      " [1.21826649e-01]\n",
      " [1.27985579e-01]\n",
      " [1.23629262e-01]\n",
      " [1.21375995e-01]\n",
      " [1.20024035e-01]\n",
      " [1.09208352e-01]\n",
      " [1.05603125e-01]\n",
      " [8.80276401e-02]\n",
      " [7.96154424e-02]\n",
      " [7.73621752e-02]\n",
      " [7.54093435e-02]\n",
      " [7.42076010e-02]\n",
      " [6.53447499e-02]\n",
      " [5.27264534e-02]\n",
      " [5.72329878e-02]\n",
      " [6.72975815e-02]\n",
      " [5.94862551e-02]\n",
      " [6.48940964e-02]\n",
      " [5.78338591e-02]\n",
      " [5.93360373e-02]\n",
      " [6.21901758e-02]\n",
      " [6.33919183e-02]\n",
      " [5.69325522e-02]\n",
      " [4.25116419e-02]\n",
      " [5.22757999e-02]\n",
      " [5.31771068e-02]\n",
      " [5.19753643e-02]\n",
      " [4.22112062e-02]\n",
      " [4.19107706e-02]\n",
      " [4.35631666e-02]\n",
      " [4.68679585e-02]\n",
      " [4.92714436e-02]\n",
      " [5.09238396e-02]\n",
      " [5.39281959e-02]\n",
      " [5.25762355e-02]\n",
      " [6.75980171e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing + Training\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"../backend/Datasets/COALINDIA.csv\")\n",
    "\n",
    "# Feature selection and preprocessing\n",
    "dropped_features = ['Date', 'Symbol', 'Series', \n",
    "                    'Trades', 'Turnover', 'Deliverable Volume', \n",
    "                    '%Deliverble', 'Last', 'VWAP', 'Prev Close']\n",
    "df.drop(dropped_features, axis=1, inplace=True)\n",
    "\n",
    "# Define features (X) and target (Y)\n",
    "X = df.drop('Close', axis=1)\n",
    "Y = df['Close']\n",
    "\n",
    "# Scale the data\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_Y = MinMaxScaler()\n",
    "X = scaler_X.fit_transform(X.values)\n",
    "Y = scaler_Y.fit_transform(Y.values.reshape(-1, 1))\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "print(f\"X_train - {X_train}\")\n",
    "print(\"*\" * 50)\n",
    "print(f\"X_test - {X_test}\")\n",
    "print(\"*\" * 50)\n",
    "\n",
    "print(f\"Y_train - {Y_train}\")\n",
    "print(\"*\" * 50)\n",
    "\n",
    "print(f\"Y_test - {Y_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e36381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_A(activation='relu', epochs=100, batch_size=32, op_learning_rate=1e-5, hidden=128, dropout=0.15):\n",
    "    # Build a neural network model with 2 hidden layers\n",
    "    # You can experiment with different architectures, including the number of layers and neurons.\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(hidden, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=op_learning_rate)  # Experiment with learning rate\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_data=(X_test, Y_test), verbose=0)\n",
    "\n",
    "    # Make predictions\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    # Inverse transform the scaled values\n",
    "    Y_test_original = scaler_Y.inverse_transform(Y_test)\n",
    "    Y_pred_original = scaler_Y.inverse_transform(Y_pred)\n",
    "\n",
    "    print(f\"Activation: {activation}\\nEpoch: {epochs}\\nBatch Size: {batch_size}\\nOptimizer learning rate: {op_learning_rate}\")\n",
    "    print(f\"Hidden: {hidden}\\nDropout: {dropout}\")\n",
    "    # Calculate MSE and R2\n",
    "    mse = mean_squared_error(Y_test_original, Y_pred_original)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    metric = tf.keras.metrics.R2Score()\n",
    "    metric.update_state(Y_test_original, Y_pred_original)\n",
    "    r2 = metric.result().numpy()\n",
    "    print(\"R^2:\", metric.result().numpy())\n",
    "    print(\"-\"*64)\n",
    "    return mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd050e4a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ret = []\n",
    "for activation in ['relu', 'sigmoid', 'tanh']:\n",
    "    for epochs in [50, 75, 100, 150]:\n",
    "        for batch_size in [24, 32, 40]:\n",
    "            for op_learning_rate in [1e-5, 1e-4, 1e-3]:\n",
    "                for hidden in [32, 64, 128]:\n",
    "                    for dropout in [0.05, 0.1, 0.15]:\n",
    "                        try:\n",
    "                            mse, r2 = create_model_A(activation=activation, epochs=epochs, batch_size=batch_size, op_learning_rate=op_learning_rate, hidden=hidden, dropout=dropout)\n",
    "                            ret.append([activation, epochs, batch_size, op_learning_rate, hidden, dropout, mse, r2])\n",
    "                        except InvalidArgumentError as e:\n",
    "                            print(\"Model error with params\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61026e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best MSE for ANN:\", sorted(ret, key=lambda x:x[-2])[0])\n",
    "print(\"Best R^2 for ANN:\", sorted(ret, key=lambda x:-x[-1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04f3a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_P(activation=None, epochs=100, batch_size=32, op_learning_rate=1e-5):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_dim=X_train.shape[1], activation=activation))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=op_learning_rate)  # Experiment with learning rate\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, Y_test), verbose=0)\n",
    "\n",
    "    # Make predictions\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    # Inverse transform the scaled values\n",
    "    Y_test_original = scaler_Y.inverse_transform(Y_test)\n",
    "    Y_pred_original = scaler_Y.inverse_transform(Y_pred)\n",
    "\n",
    "    print(f\"Activation: {activation}\\nEpoch: {epochs}\\nBatch Size: {batch_size}\\nOptimizer learning rate: {op_learning_rate}\")\n",
    "    # Calculate MSE\n",
    "    mse = mean_squared_error(Y_test_original, Y_pred_original)\n",
    "    print(f\"Mean Squared Error (Perceptron): {mse}\")\n",
    "    metric = tf.keras.metrics.R2Score()\n",
    "    metric.update_state(Y_test_original, Y_pred_original)\n",
    "    r2 = metric.result().numpy()\n",
    "    print(\"R^2:\", metric.result().numpy())\n",
    "    print(\"-\"*64)\n",
    "    return mse, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c36e7d73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 316us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 50\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 1392.6992577453946\n",
      "R^2: 0.28688818\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 298us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 50\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 5276.005876701099\n",
      "R^2: -1.7015038\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 275us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 50\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 10.61555730477912\n",
      "R^2: 0.9945645\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 327us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 50\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 526.2100493607261\n",
      "R^2: 0.7305616\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 293us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 50\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 3655.665697347731\n",
      "R^2: -0.87183154\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 304us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 50\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 1120.4088516509232\n",
      "R^2: 0.42631054\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 305us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 50\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 33099.950257835066\n",
      "R^2: -15.94836\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 306us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 50\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 1814.1746798389825\n",
      "R^2: 0.071077585\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 310us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 50\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 7787.411109472357\n",
      "R^2: -2.9874332\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 307us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 75\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 4747.144628804292\n",
      "R^2: -1.4307077\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 289us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 75\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 134.3934579268669\n",
      "R^2: 0.9311857\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 312us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 75\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 17.441307086896416\n",
      "R^2: 0.99106944\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 10:50:57.072838: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at resource_variable_ops.cc:597 : INVALID_ARGUMENT: Cannot update variable with shape [] using a Tensor with shape [0], shapes must be equal.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered with configuration: Activation=None, Epochs=75, Batch size=32, Learning rate=1e-05, Hidden=128, Dropout=0.1\n",
      "Graph execution error:\n",
      "\n",
      "Detected at node AssignAddVariableOp defined at (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "\n",
      "  File \"/var/folders/zw/mhjv893s7v34n36w_xlsnq2w0000gn/T/ipykernel_67298/1580189334.py\", line 7, in <module>\n",
      "\n",
      "  File \"/var/folders/zw/mhjv893s7v34n36w_xlsnq2w0000gn/T/ipykernel_67298/4117936375.py\", line 10, in create_model_P\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1832, in fit\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2272, in evaluate\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 4079, in run_step\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2042, in test_function\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2025, in step_function\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2013, in run_step\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1895, in test_step\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 329, in __call__\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/metrics/base_metric.py\", line 528, in update_state\n",
      "\n",
      "Cannot update variable with shape [] using a Tensor with shape [0], shapes must be equal.\n",
      "\t [[{{node AssignAddVariableOp}}]] [Op:__inference_test_function_1245511]\n",
      "17/17 [==============================] - 0s 299us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 75\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 7335.835654539274\n",
      "R^2: -2.7562103\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 306us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 75\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 9.957032419051583\n",
      "R^2: 0.99490166\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 298us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 75\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 1810.6279869811517\n",
      "R^2: 0.07289374\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 319us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 75\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 1483.8711772537729\n",
      "R^2: 0.24020487\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 331us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 75\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 3.71346282272757\n",
      "R^2: 0.99809855\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 309us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 100\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 835.9634672686382\n",
      "R^2: 0.57195675\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 302us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 100\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 9388.6670550963\n",
      "R^2: -3.807334\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 307us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 100\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 11.002858072570696\n",
      "R^2: 0.99436617\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 287us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 100\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 1212.5172317297468\n",
      "R^2: 0.3791477\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 296us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 100\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 2387.3827447311155\n",
      "R^2: -0.22242534\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 355us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 100\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 60.38625135158539\n",
      "R^2: 0.9690801\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 319us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 100\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 11553.35814525464\n",
      "R^2: -4.915733\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 343us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 100\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 995.0624885901668\n",
      "R^2: 0.4904924\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 348us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 100\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 3.880477842545045\n",
      "R^2: 0.9980131\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 322us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 150\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 49202.762258153445\n",
      "R^2: -24.193575\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 338us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 150\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 5473.365561160367\n",
      "R^2: -1.8025589\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 297us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 150\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 18.25527489125925\n",
      "R^2: 0.9906526\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 321us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 150\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 1433.9118003965777\n",
      "R^2: 0.26578575\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 309us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 150\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 6500.820077523151\n",
      "R^2: -2.3286526\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 313us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 150\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 9.936894215935757\n",
      "R^2: 0.99491197\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 309us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 150\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 2887.0737877395077\n",
      "R^2: -0.4782852\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 295us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 150\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 5.190241257969248\n",
      "R^2: 0.9973424\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 323us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: None\n",
      "Epoch: 150\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 9.632463744796151\n",
      "R^2: 0.99506783\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 310us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 50\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 5368.853843415024\n",
      "R^2: -1.7490454\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 311us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 50\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 5389.570142197838\n",
      "R^2: -1.7596531\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 314us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 50\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 25.630138153428938\n",
      "R^2: 0.9868764\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 319us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 50\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 5389.492935224799\n",
      "R^2: -1.7596135\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 314us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 50\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 2474.231562785094\n",
      "R^2: -0.26689506\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 319us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 50\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 3.255831582301545\n",
      "R^2: 0.9983329\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 315us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 50\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 3574.4026401217\n",
      "R^2: -0.830222\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 307us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 50\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 5289.342693941913\n",
      "R^2: -1.7083328\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 325us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 50\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 7.172784392739845\n",
      "R^2: 0.9963273\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 294us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 75\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 5389.574218676504\n",
      "R^2: -1.759655\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 282us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 75\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 2181.5107277699412\n",
      "R^2: -0.11701155\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 327us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 75\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 16.383832942611626\n",
      "R^2: 0.9916109\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 343us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 75\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 2430.729021510376\n",
      "R^2: -0.24462044\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 343us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 75\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 5389.5954065814\n",
      "R^2: -1.759666\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 301us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 75\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 5387.872756333625\n",
      "R^2: -1.7587838\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 292us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 75\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 493.7641629606643\n",
      "R^2: 0.7471751\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 307us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 75\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 441.276103794077\n",
      "R^2: 0.77405083\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 333us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 75\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 5389.531350585034\n",
      "R^2: -1.7596331\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 319us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 100\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 389.36989672716555\n",
      "R^2: 0.80062866\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 310us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 100\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 5389.570137614477\n",
      "R^2: -1.7596531\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 312us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 100\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 2.433506392215883\n",
      "R^2: 0.99875396\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 325us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 100\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 239.15731485424433\n",
      "R^2: 0.8775429\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 351us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 100\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 283.51645094510974\n",
      "R^2: 0.85482943\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 344us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 100\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 11.748972324424662\n",
      "R^2: 0.9939841\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 332us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 100\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 82.16342980972803\n",
      "R^2: 0.9579294\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 329us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 100\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 559.3452738215096\n",
      "R^2: 0.71359515\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 357us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 100\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 5389.570142197838\n",
      "R^2: -1.7596531\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 345us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 150\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 5389.5730225899215\n",
      "R^2: -1.7596543\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 316us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 150\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 47.98988943643656\n",
      "R^2: 0.97542745\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 297us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 150\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 9.255369239807134\n",
      "R^2: 0.9952609\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 278us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 150\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 5363.505884613868\n",
      "R^2: -1.7463071\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 342us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 150\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 12.112428205060843\n",
      "R^2: 0.993798\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 10:54:09.333560: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at resource_variable_ops.cc:597 : INVALID_ARGUMENT: Cannot update variable with shape [] using a Tensor with shape [0], shapes must be equal.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered with configuration: Activation=relu, Epochs=150, Batch size=32, Learning rate=0.001, Hidden=128, Dropout=0.1\n",
      "Graph execution error:\n",
      "\n",
      "Detected at node AssignAddVariableOp defined at (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "\n",
      "  File \"/var/folders/zw/mhjv893s7v34n36w_xlsnq2w0000gn/T/ipykernel_67298/1580189334.py\", line 7, in <module>\n",
      "\n",
      "  File \"/var/folders/zw/mhjv893s7v34n36w_xlsnq2w0000gn/T/ipykernel_67298/4117936375.py\", line 10, in create_model_P\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1832, in fit\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2272, in evaluate\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 4079, in run_step\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2042, in test_function\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2025, in step_function\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2013, in run_step\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1895, in test_step\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 329, in __call__\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n",
      "\n",
      "  File \"/Users/nayeelimtiaz/anaconda3/lib/python3.11/site-packages/keras/src/metrics/base_metric.py\", line 528, in update_state\n",
      "\n",
      "Cannot update variable with shape [] using a Tensor with shape [0], shapes must be equal.\n",
      "\t [[{{node AssignAddVariableOp}}]] [Op:__inference_test_function_2807854]\n",
      "17/17 [==============================] - 0s 339us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 150\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 5389.570142197838\n",
      "R^2: -1.7596531\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 325us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 150\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 3057.0258355972737\n",
      "R^2: -0.56530654\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 335us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "Epoch: 150\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 2.648684914167957\n",
      "R^2: 0.99864376\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 304us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: sigmoid\n",
      "Epoch: 50\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 13952.173082325944\n",
      "R^2: -6.144012\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 333us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: sigmoid\n",
      "Epoch: 50\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 11710.982347041985\n",
      "R^2: -4.996442\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 291us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: sigmoid\n",
      "Epoch: 50\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 718.4272152062391\n",
      "R^2: 0.63213956\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 297us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: sigmoid\n",
      "Epoch: 50\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 14303.166718143548\n",
      "R^2: -6.323734\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 317us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: sigmoid\n",
      "Epoch: 50\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 18246.67138664089\n",
      "R^2: -8.342949\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 357us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: sigmoid\n",
      "Epoch: 50\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 10352.260192431671\n",
      "R^2: -4.3007274\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 332us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: sigmoid\n",
      "Epoch: 50\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 12089.178251248231\n",
      "R^2: -5.190092\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 331us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: sigmoid\n",
      "Epoch: 50\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 18349.200473174562\n",
      "R^2: -8.395447\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 331us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: sigmoid\n",
      "Epoch: 50\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 9595.110850560339\n",
      "R^2: -3.9130406\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 344us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: sigmoid\n",
      "Epoch: 75\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 14205.404203246266\n",
      "R^2: -6.273676\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 323us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: sigmoid\n",
      "Epoch: 75\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 23718.71296537388\n",
      "R^2: -11.14483\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 307us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: sigmoid\n",
      "Epoch: 75\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 264.0992076105329\n",
      "R^2: 0.8647717\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 310us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: sigmoid\n",
      "Epoch: 75\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 11674.934144297082\n",
      "R^2: -4.977984\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 304us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: sigmoid\n",
      "Epoch: 75\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 21446.896449957138\n",
      "R^2: -9.981579\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 325us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: sigmoid\n",
      "Epoch: 75\n",
      "Batch Size: 32\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 3146.6543093811956\n",
      "R^2: -0.6111995\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 338us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: sigmoid\n",
      "Epoch: 75\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 14022.4445768852\n",
      "R^2: -6.179993\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 314us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: sigmoid\n",
      "Epoch: 75\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 0.0001\n",
      "Mean Squared Error (Perceptron): 19261.420051346664\n",
      "R^2: -8.862537\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 325us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: sigmoid\n",
      "Epoch: 75\n",
      "Batch Size: 40\n",
      "Optimizer learning rate: 0.001\n",
      "Mean Squared Error (Perceptron): 1378.273430309472\n",
      "R^2: 0.29427463\n",
      "----------------------------------------------------------------\n",
      "17/17 [==============================] - 0s 336us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: sigmoid\n",
      "Epoch: 100\n",
      "Batch Size: 24\n",
      "Optimizer learning rate: 1e-05\n",
      "Mean Squared Error (Perceptron): 15430.521115378418\n",
      "R^2: -6.9009786\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m op_learning_rate \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1e-5\u001b[39m, \u001b[38;5;241m1e-4\u001b[39m, \u001b[38;5;241m1e-3\u001b[39m]:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m         mse, r2 \u001b[38;5;241m=\u001b[39m create_model_P(activation\u001b[38;5;241m=\u001b[39mactivation, epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, op_learning_rate\u001b[38;5;241m=\u001b[39mop_learning_rate)\n\u001b[1;32m      8\u001b[0m         ret\u001b[38;5;241m.\u001b[39mappend([activation, epochs, batch_size, op_learning_rate, mse, r2])\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m InvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m, in \u001b[0;36mcreate_model_P\u001b[0;34m(activation, epochs, batch_size, op_learning_rate)\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train, epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, validation_data\u001b[38;5;241m=\u001b[39m(X_test, Y_test), verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m     13\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:140\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1449\u001b[0m, in \u001b[0;36mConcreteFunction.captured_inputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcaptured_inputs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns external Tensors captured by this function.\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \n\u001b[1;32m   1447\u001b[0m \u001b[38;5;124;03m  self.__call__(*args) passes `args + self.captured_inputs` to the function.\u001b[39;00m\n\u001b[1;32m   1448\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1449\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mflatten(\n\u001b[1;32m   1450\u001b[0m       [x() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_captured_inputs],\n\u001b[1;32m   1451\u001b[0m       expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/nest.py:294\u001b[0m, in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.flatten\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten\u001b[39m(structure, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    201\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a flat list from a given structure.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    TypeError: The nest is or contains a dict with non-sortable keys.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m nest_util\u001b[38;5;241m.\u001b[39mflatten(\n\u001b[1;32m    295\u001b[0m       nest_util\u001b[38;5;241m.\u001b[39mModality\u001b[38;5;241m.\u001b[39mCORE, structure, expand_composites\n\u001b[1;32m    296\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:815\u001b[0m, in \u001b[0;36mflatten\u001b[0;34m(modality, structure, expand_composites)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Flattens a nested structure.\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;124;03m  TypeError: The nest is or contains a dict with non-sortable keys.\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m--> 815\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_flatten(structure, expand_composites)\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m    817\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_flatten(structure)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:829\u001b[0m, in \u001b[0;36m_tf_core_flatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    827\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    828\u001b[0m expand_composites \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(expand_composites)\n\u001b[0;32m--> 829\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _pywrap_utils\u001b[38;5;241m.\u001b[39mFlatten(structure, expand_composites)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ret = []\n",
    "for activation in [None, 'relu', 'sigmoid', 'tanh']:\n",
    "    for epochs in [50, 75, 100, 150]:\n",
    "        for batch_size in [24, 32, 40]:\n",
    "            for op_learning_rate in [1e-5, 1e-4, 1e-3]:\n",
    "                try:\n",
    "                    mse, r2 = create_model_P(activation=activation, epochs=epochs, batch_size=batch_size, op_learning_rate=op_learning_rate)\n",
    "                    ret.append([activation, epochs, batch_size, op_learning_rate, mse, r2])\n",
    "                except InvalidArgumentError as e:\n",
    "                    print(\"Model error with params\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c804f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best MSE for Perceptron:\", sorted(ret, key=lambda x:x[-2])[0])\n",
    "print(\"Best R^2 for Perceptron:\", sorted(ret, key=lambda x:-x[-1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a82d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_D(activation='tanh', epochs=100, batch_size=32, op_learning_rate=1e-5, hidden=128, layers=11, dropout=0.1):\n",
    "    # Build a neural network model with 2 hidden layers\n",
    "    # You can experiment with different architectures, including the number of layers and neurons.\n",
    "    # Building DNN model with 11 hidden layers\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer\n",
    "    # Input layer will have same number of neurons as number of feature variables\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], activation=activation))\n",
    "\n",
    "    # Hidden layers\n",
    "    # Play around with number of neurons in each hidden layer.\n",
    "    # Too many neurons leads to overcomplexity, not enough means too simple\n",
    "    # Tanh activation function here is used b/c it is recommended to use\n",
    "    # when there are more hidden layers.\n",
    "    for _ in range(layers-1):\n",
    "        model.add(Dense(hidden, activation=activation))\n",
    "        model.add(Dropout(dropout)) # This helps with preventing overfitting\n",
    "\n",
    "    # Output layer\n",
    "    # Output layer will have 1 neuron b/c there's only 1 target variable\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=op_learning_rate)  # Experiment with learning rate\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_data=(X_test, Y_test), verbose=0)\n",
    "\n",
    "    # Make predictions\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    # Inverse transform the scaled values\n",
    "    Y_test_original = scaler_Y.inverse_transform(Y_test)\n",
    "    Y_pred_original = scaler_Y.inverse_transform(Y_pred)\n",
    "\n",
    "    print(f\"Activation: {activation}\\nEpoch: {epochs}\\nBatch Size: {batch_size}\\nOptimizer learning rate: {op_learning_rate}\")\n",
    "    print(f\"Hidden: {hidden}\\nLayers: {layers}\\nDropout: {dropout}\")\n",
    "    # Calculate MSE and R2\n",
    "    mse = mean_squared_error(Y_test_original, Y_pred_original)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    metric = tf.keras.metrics.R2Score()\n",
    "    metric.update_state(Y_test_original, Y_pred_original)\n",
    "    r2 = metric.result().numpy()\n",
    "    print(\"R^2:\", metric.result().numpy())\n",
    "    print(\"-\"*64)\n",
    "    return mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064960be",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, r = create_model_D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ba123",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# GRID SEARCH\n",
    "\n",
    "ret = []\n",
    "for activation in ['relu', 'sigmoid', 'tanh']:\n",
    "    for epochs in [50, 75, 100, 150]:\n",
    "        for batch_size in [24, 32, 40]:\n",
    "            for op_learning_rate in [1e-5, 1e-4, 1e-3]:\n",
    "                for hidden in [32, 64, 128]:\n",
    "                    for layers in [6, 9, 11]:\n",
    "                        for dropout in [0.05, 0.1, 0.15]:\n",
    "                            try:\n",
    "                                mse, r2 = create_model_D(activation=activation, epochs=epochs, batch_size=batch_size, op_learning_rate=op_learning_rate, hidden=hidden, layers=layers, dropout=dropout)\n",
    "                                ret.append([activation, epochs, batch_size, op_learning_rate, hidden, layers, dropout, mse, r2])\n",
    "                            except:\n",
    "                                print(\"Model error with params\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ece162",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best MSE for DNN:\", sorted(ret, key=lambda x:x[-2])[0])\n",
    "print(\"Best R^2 for DNN:\", sorted(ret, key=lambda x:-x[-1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a78a21e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
